---
layout: post
title: NUGUMate
---

### Members

Chang Hee Kim, Department of Information System, Hanyang University  
Taek Joon Kim, Department of Information System, Hanyang University  
Hyun Kook Jeon, Department of Information System, Hanyang University  
Heon Nam Chu, Department of Information System, Hanyang University  

### Introduction

- Motivation

 SKT의 조사에 따르면, 1인 가구의 수가 증가함에 따라 사용자가 인공지능 스피커를 커뮤니케이션의 대상으로 생각하는 경향이 높아지고 있고, 그들이 개인적인 경험을 AI 스피커와 공유할 때 더욱 친밀감을 느낀다. 즉, 사용자는 단순한 명령 수행 및 정보 습득 뿐만 아니라, AI 스피커와 친밀한 관계를 형성하고 심리적 안정감을 얻기를 기대하고 있다.  
 본 프로젝트에서는 이러한 사용자들의 수요를 반영하여 NUGU AI 스피커와 사용자가 유대 관계를 형성하고 '친구'로서의 관계를 맺는 것을 목적으로 한다. 먼저, 사용자가 자신이 하루 동안 느꼈던 감정을 일기로 작성하면 이에 대해 감정 분석을 진행하여 각 일기의 내용을 긍정 혹은 부정으로 분류한다. 사용자가 "아리아, 오늘 하루는 어땠어?" 와 같이 발화를 시작하면, NUGU 스피커는 감정 분석 결과를 토대로 "주인님의 감정이 안 좋은 것 같아서 저도 우울했어요."처럼 사용자의 감정에 공감할 수 있는 답변을 제공한다. 이렇게 사용자로 하여금 NUGU 스피커와 상호 작용하고 있다는 느낌을 제공하여 NUGU 스피커에 대한 의존도를 높이고, NUGU 스피커의 활용 범위를 보다 확장하고자 한다.  
 
 
- NUGUMate의 작동 방식

![_config.yml]({{ site.baseurl }}/images/brief_interaction_database.png)  

 NUGUMate의 작동 방식은 아래와 같다. 
 1. 사용자가 애플리케이션에 일기를 작성하면 애플리케이션은 해당 일기의 내용, 일기가 작성된 날짜, 사용자 정보를 서버에 전송한다. 
 2. 서버는 애플리케이션으로부터 받은 정보를 데이터베이스에 저장한다. 
 3. 데이터베이스에 저장된 일기를 불러온 후, 다른 서버와 연동된 감정 분석 모델을 이용하여 해당 일기의 각 문장에 담긴 감정을 긍정 혹은 부정으로 분류한다. 감정 분류 결과를 해당 일기가 저장된 곳에 추가한다. 
 4. 이 후, 사용자가 NUGU 디바이스에 “아리아, 오늘 하루는 어땠어?” 와 같이 일상의 대화를 시작할 경우 NUGU 디바이스는 “주인님의 감정이 안 좋은 것 같아서 저도 우울했어요.” 와 같이 감정 분석 모델의 결과를 바탕으로 사용자의 감정에 공감할 수 있는 답변을 제공한다. 사용자는 조회한 날짜 당일과 더불어 조회한 날짜에 해당하는 주와 달에 대해서도 동일한 대화를 진행할 수 있다. 즉, “아리아, 이번 주는 어땠어?” 혹은 “아리아, 이번 달은 어땠어?” 와 같은 질문에 대해서도 동일한 방식의 답을 제공한다.

### Datasets
- Model용 Datasets
   감정 분석 모델을 구현하기 위해서는 우선 모델 레이어를 만들고 데이터셋을 이용하여 학습을 진행하여야 한다.
   학습 및 평가를 위한 데이터셋으로는 네이버 영화 리뷰글을 긍정적/부정적 의견으로 분류한 데이터셋(.txt 파일)을 사용하였다.
   1. ratings.txt
   
      10만개의 긍정 리뷰와 10만개의 부정 리뷰로 나누어져 있다. (총 20만개)
      각 column마다 id값, 리뷰 문장, 0(부정) 또는 1(긍정)의 결과값으로 구성되어 있다.
      
   2. ratings_train.txt
   
      총 15만개의 리뷰로 구성되어 있다. (모델 학습용)
      
   3. ratings_test.txt
   
      총 5만개의 리뷰로 구성되어 있다. (모델 평가용)

### Methodology

- Explaining your choice of algorithms (methods)
- Explaining features or code (if any)
- Model
   - 사용한 외부 라이브러리  
   1. konlpy  
   
      문장의 형태소 분석 및 단어 추출을 위해 konlpy 안에 있는 Okt 클래스를 이용하였다.
   
   2. numpy, nltk  
   
   
      Dataset의 전처리를 위해 이용하였다.
   
   3. tensorflow, keras  
   
      모델의 생성 및 학습을 위해 이용하였다.
   
   
   - 모델 생성 과정 및 이용
   1. 데이터의 전처리 (형태소 분석 및 json 파일 생성) -> txt_preprocessing.py
   ```python
   from konlpy.tag import Okt
   import json
   import datetime
   import sys

   c_time = datetime.datetime.now()
   cur_time = c_time.strftime("%Y_%m_%d_%H_%M_%S__")
   parser = Okt()
   
   
   # Read txt file
   def read_data(txt_file):
       with open(txt_file, "r") as f:
           raw_data = f.read().splitlines()
           data = [line.split("\t") for line in raw_data]
           data = data[1:]
       return data
   
   
   # Only word, except josa
   def tokenize(doc):
       return [t[0] for t in parser.pos(doc, norm=True, stem=True)]
   
   
   # Read data and put it to raw_doc
   target = "txt_files/" + sys.argv[1] + ".txt"
   raw_doc = read_data(target)
   
   # Tokenized words and output result(0 or 1)
   data_set = [[tokenize(doc[1]), doc[2]] for doc in raw_doc]
   
   # Make a json file
   file_name = "json_files/" + sys.argv[1] + "_dset.json"
   with open(file_name, "w") as make_file:
       json.dump(data_set, make_file, ensure_ascii=False, indent="  ")
   
   print("Preprocessing complete.")
   ```
     
   
   
   txt 파일에서 학습 및 평가에 불필요한 id colomn을 제거하고, 각 문장마다 등장한 단어 목록 리스트, 긍정/부정 결과값으로
   이루어진 리스트를 만들어낸다. 그리고 그 전체 리스트를 json 파일로 만들어 저장해놓는다.
      
   학습 및 테스트를 위해 ratings_train.txt와 ratings_test.txt 두 파일에 전처리를 진행하고, 두 개의 json 파일을 만든다.
   -> ratings_train_dset.json, ratings_test_dset.json
      
   내용 형태 -> [  [ [단어1, 단어2...] , 0 or 1 ] , [ [단어1, 단어2....] , 0 or 1 ] , ....... [ [단어1, 단어2] , 0 or 1 ]  ]

   2. 데이터의 전처리 (Vectorization) -> learning_model.py
   ```python
   import json
   import sys
   import nltk
   import datetime
   import numpy as np
   from keras import models, layers, optimizers, losses, metrics
   
   
   target = "json_files/ratings_train_dset.json"
   # Loading json file
   with open(target) as f:
       train_target = json.load(f)
   
   # Only tokens
   train_tokens = [tok for d in train_target for tok in d[0]]
   train_text = nltk.Text(train_tokens, name="train_t")
   
   # Make selected_word <- This is used to make vector
   common_tests = train_text.vocab().most_common(100)
   selected_word = [word[0] for word in common_tests]
   
   
   def term_frequency(doc):
       return [doc.count(s_word) for s_word in selected_word]
   
   
   # Vectorization
   # x is input (term), and it is dataset
   train_x = [term_frequency(d) for d, _ in train_target]
   # y is output (0 or 1), and it is dataset
   train_y = [c for _, c in train_target]
   
   # Change x and y to float type data
   train_x = np.asarray(train_x).astype("float32")
   train_y = np.asarray(train_y).astype("float32")
   
   # Initialize model
   model = models.Sequential()
   # Add layers to model(Output size, activation function, input size)
   model.add(layers.Dense(64, activation="relu", input_shape=(100,)))
   model.add(layers.Dense(64, activation="relu"))
   model.add(layers.Dense(1, activation="sigmoid"))
   # Set method of learning and evaluation (Gradient descent, error function, evaluation indicator)
   model.compile(optimizer=optimizers.RMSprop(lr=0.001),
                 loss=losses.binary_crossentropy,
                 metrics=[metrics.binary_accuracy])
   
   # Start learning (Input, output, number of trial, size of input at once
   model.fit(train_x, train_y, epochs=30, batch_size=1024)
   print("Learning complete.")
   
   # Save model
   c_time = datetime.datetime.now()
   cur_time = c_time.strftime("%Y_%m_%d_%H_%M_%S__")
   model_name = "NLP_model/learned_model.h5"
   model.save(model_name)
   # Save selected_word in json file
   with open("NLP_model/selected_word.json", "w") as sf:
       json.dump(selected_word, sf, ensure_ascii=False)
   print("Model is saved.")
   ```
   
   
   ratings_train_dset.json 파일을 로드하고 그 내용을 train_target에 저장한다.
      
   벡터화를 위해 기준이 되는 단어 list를 만들어낸다. -> selected_word
      
   (train_target 전체에 등장한 단어들 중에서 등장 빈도수가 가장 높은 상위 100개의 단어들로 구성하였다.)
      
   그 후 term_frequency 함수를 통해 train_target 안의 각 문장 단어 리스트에서
   selected_word 안에 있는 단어의 등장 빈도를 나타내는 train_x(type: list)를 만든다.
   train_y는 train_target에 있는 긍정/부정 결과값들의 list이다.
      
   마지막으로 train_x와 train_y 값을 float 형식으로 바꿔준다.
      
   3. 모델 생성 및 학습 -> learning_model.py (위 코드 참조)
      
   모델을 생성하고, 신경망 레이어를 3개 추가한다. 활성화 함수는 마지막 층에는 sigmoid를, 나머지 층들은 relu를 사용하였다.
      
   학습 및 평가 방법을 지정해야 하는데, 경사 하강법으로는 RMSprop을, 오차 함수는 이진 분류에 사용되는 binary_crossentropy를,
   평가 지표로는 정확도를 지정하였다.
      
   입력, 출력 데이터(train_x, train_y)를 넣고 학습을 시작한다.
      
   epoth(반복 횟수)는 30, batch_size(한번에 들어가는 입력의 크기)는 1024로 설정하였다.
      
   학습이 완료되면 모델(아키텍쳐 및 가중치 값 포함)을 h5 형식의 파일로 저장한다.
      
   4. 모델 평가 -> testing_model.py
   ```python
   import json
   import sys
   import numpy as np
   from keras.models import load_model
   
   target_model = "NLP_model/learned_model.h5"
   target_json = "json_files/ratings_test_dset.json"
   # Load json file for test
   with open(target_json) as f:
       test_target = json.load(f)
   
   # Load selected_word
   with open("NLP_model/selected_word.json", "r") as sf:
       selected_word = json.load(sf)
   # Load model
   model = load_model(target_model)
   
   
   def term_frequency(doc):
       return [doc.count(s_word) for s_word in selected_word]
   
   
   # Vectorization
   # x is input (term), and it is dataset
   test_x = [term_frequency(d) for d, _ in test_target]
   # y is output (0 or 1), and it is dataset
   test_y = [c for _, c in test_target]
   
   # Change x and y to float type data
   test_x = np.asarray(test_x).astype("float32")
   test_y = np.asarray(test_y).astype("float32")
   
   # Evaluate model with test dataset
   result = model.evaluate(test_x, test_y)
   test_accuracy = result[1] * 100
   print("Accuracy is {:.2f}%".format(test_accuracy))
   ```
   
   
   학습 완료된 모델 및 ratings_tset_dset.json을 불러온 후 evaluate()를 통해 테스트 데이터 셋에 대한 정확도를 측정한다.
         
   실행 결과 77.96%의 정확도를 나타내었다.
         
   5. 모델의 활용 -> main_model.py
   ```python
   import json
   import numpy as np
   from konlpy.tag import Okt
   from keras.models import load_model
   
   parser = Okt()
   target_model = "NLP_model/learned_model.h5"
   
   # Load selected_word
   with open("NLP_model/selected_word.json", "r") as sf:
       selected_word = json.load(sf)
   # Load model
   model = load_model(target_model)
   
   
   def tokenize(sentence):
       list = [t[0] for t in parser.pos(sentence, norm=True, stem=True)]
       return list
   
   
   # selected_word 안에 있는 word들이 각각 얼마나 나왔나
   def term_frequency(doc):
       return [doc.count(word) for word in selected_word]
   
   
   def calculate_sentiment_single_diary(sent):
       tokens = tokenize(sent)
       tf = term_frequency(tokens)
       data = np.expand_dims(np.asarray(tf).astype("float32"), axis=0)
       score = float(model.predict(data))
       if score > 0.5:
           return 1
       else:
           return 0
   ```
   
   calculate_sentiment_single_diary()를 포함하고 있다. Parameter 값으로 들어온 문장에 대해 감정 분석을 실시하고 결과값을 반환한다.



### Evaluation & Analysis

- Graphs, tables, any statistics (if any)

### Related Work

- Tools, libraries, blogs, or any documentation that you have used to do this project.

### Conclusion

contents
